{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of aipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from tinydb import Query\n",
    "\n",
    "from aipy.ai import *\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the DB of existing chats, and summarize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----------------+-------------------------------+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "|         Name        |       Date      |             Topics            |                                                            Summary                                                            |\n",
      "+---------------------+-----------------+-------------------------------+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Code_Chatbot_OpenAI | 20230528_174323 | ['Code', 'Chatbot', 'OpenAI'] | This chat, named \"CodeChat\", is a chatbot designed to interact with and provide assistance on code using the OpenAI chat API. |\n",
      "+---------------------+-----------------+-------------------------------+-------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Name</th>\n",
       "            <th>Date</th>\n",
       "            <th>Topics</th>\n",
       "            <th>Summary</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Code_Chatbot_OpenAI</td>\n",
       "            <td>20230528_174323</td>\n",
       "            <td>[&#x27;Code&#x27;, &#x27;Chatbot&#x27;, &#x27;OpenAI&#x27;]</td>\n",
       "            <td>This chat, named &quot;CodeChat&quot;, is a chatbot designed to interact with and provide assistance on code using the OpenAI chat API.</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+---------------------+-----------------+-------------------------------+-------------------------------------------------------------------------------------------------------------------------------+\n",
       "|         Name        |       Date      |             Topics            |                                                            Summary                                                            |\n",
       "+---------------------+-----------------+-------------------------------+-------------------------------------------------------------------------------------------------------------------------------+\n",
       "| Code_Chatbot_OpenAI | 20230528_174323 | ['Code', 'Chatbot', 'OpenAI'] | This chat, named \"CodeChat\", is a chatbot designed to interact with and provide assistance on code using the OpenAI chat API. |\n",
       "+---------------------+-----------------+-------------------------------+-------------------------------------------------------------------------------------------------------------------------------+"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = ChatDB('chats.json')\n",
    "db.summarise()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start a new chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_chat = CodeInspector('../aipy/ai.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Certainly! Here is a concise docstring for the file along with separate docstrings for every class and method:\\n\\n```\\n\"\"\"\\nThis module provides classes for managing chat logs and code inspection.\\n\\nClasses:\\n- Chat: Represents a chat log and provides methods for interacting with OpenAI\\'s GPT-3 API.\\n- CodeInspector: Represents a code file and provides methods for asking questions about the code.\\n- ChatDB: Represents a database of chat logs and provides methods for storing and searching logs.\\n\\nMethods:\\n- load_chat(path): Loads a Chat object from a pickle file at the given path.\\n\"\"\"\\n```\\n\\n`Chat` class:\\n\\n``` \\n\"\"\"\\nRepresents a chat log and provides methods for interacting with OpenAI\\'s GPT-3 API.\\n\\nAttributes:\\n- messages: A list of dictionaries representing the chat messages, \\nwith each dictionary containing \\'role\\' and \\'content\\' keys.\\n\"\"\"\\n\\ndef __init__(self, messages=None) -> None:\\n    \"\"\"Initializes a new Chat object with the given messages, \\n    or a default message if none are provided.\"\"\"\\n\\ndef ask(self, question, max_tokens=2000, model=DEFAULT_MODEL, temperature=1, keep=True) -> str:\\n    \"\"\"Sends a message to the GPT-3 API and returns the response.  \\n    By default append the prompt and response to the chat history\"\"\" \\n\\ndef get_topics(self) -> list:\\n    \"\"\"Asks the chatgpt to provide up to three descriptive topics for the chat and returns them as a list.\"\"\"\\n\\ndef suggest_filename(self):\\n    \"\"\"Generates a suggested filename for saving the chat log.\"\"\"\\n\\ndef summarise(self):\\n    \"\"\"Asks the chatgpt to describe the chat in one sentence and returns the response.\"\"\"\\n\\ndef save(self, path=None, directory=\\'.\\'):\\n    \"\"\"Save the chat to messages to a pickle (can be loaded again with load_chat)\"\"\"\\n\\ndef format(self) -> str:\\n    \"\"\"For mat the conversation text\"\"\"\\n\\ndef print(self) -> None:\\n    \"print formatted text of the conversation to screen\"\\n\\ndef write_txt(self, path=None, directory=\\'.\\'):\\n    \"write formatted text of the converstaion to file\"\\n``` \\n\\n`CodeInspector` class:\\n\\n```\\n\"\"\"\\nSubclass of Chat for inspecting a source code file\\n\"\"\"\\n\\ndef __init__(self, code_path) -> None:\\n    \"\"\"Initializes a new CodeInspector object with the given code file path.\"\"\"\\n\\ndef describe(self, temperature=0.2):\\n    \"\"\"Asks the chatgpt to describe the purpose and algorithm for this code\"\"\"\\n```\\n\\n`ChatDB` class:\\n\\n``` \\n\"\"\"\\nRepresents a database of chat logs and provides methods for storing and searching logs.\\n\"\"\"\\n\\ndef __init__(self, path = None) -> None:\\n    \"\"\"\\n    Initializes a new ChatDB object with the database at the given path, or a default path if none is provided.\\n\\n    Args:\\n    - path: The path to the database.\\n    \"\"\"\\n\\ndef store(self, chat: Chat, topics = []) -> None:\\n    \"\"\"\\n    Stores the given Chat object in the database.\\n\\n    Args:\\n    - chat: The Chat object to store.\\n    \"\"\"\\n\\ndef summarise(self) -> PrettyTable:\\n    \"\"\"\\n    Prints a summary of all chats in the database to the console and returns a PrettyTable object.\\n\\n    Returns:\\n    - A PrettyTable object representing the summary of all chats in the database.\\n    \"\"\"\\n\\ndef search(self, query) -> list:\\n    \"\"\"\\n    Searches the database for chats matching the given query and returns a list of Chat objects.\\n\\n    Args:\\n    - query: The query to search for.\\n\\n    Returns:\\n    - A list of Chat objects matching the query.\\n    \"\"\"\\n\\ndef close(self) -> None:\\n    \"\"\"\\n    Closes the database connection.\\n    \"\"\"\\n``` \\n\\n`load_chat` function:\\n\\n```\\n\"\"\"\\nLoads a Chat object from a pickle file at the given path.\\n\\nArgs:\\n- path: The path to the pickle file.\\n\\nReturns:\\n- A Chat object.\\n\"\"\"\\n```'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chat.ask('can you please provide a concise docstring for the file, with a separate docstring for every class and method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can you please provide a concise docstring for the file, with a separate docstring for every class and method\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "Certainly! Here is a concise docstring for the file along with separate docstrings for every class and method:\n",
      "\n",
      "```\n",
      "\"\"\"\n",
      "This module provides classes for managing chat logs and code inspection.\n",
      "\n",
      "Classes:\n",
      "- Chat: Represents a chat log and provides methods for interacting with OpenAI's GPT-3 API.\n",
      "- CodeInspector: Represents a code file and provides methods for asking questions about the code.\n",
      "- ChatDB: Represents a database of chat logs and provides methods for storing and searching logs.\n",
      "\n",
      "Methods:\n",
      "- load_chat(path): Loads a Chat object from a pickle file at the given path.\n",
      "\"\"\"\n",
      "```\n",
      "\n",
      "`Chat` class:\n",
      "\n",
      "``` \n",
      "\"\"\"\n",
      "Represents a chat log and provides methods for interacting with OpenAI's GPT-3 API.\n",
      "\n",
      "Attributes:\n",
      "- messages: A list of dictionaries representing the chat messages, \n",
      "with each dictionary containing 'role' and 'content' keys.\n",
      "\"\"\"\n",
      "\n",
      "def __init__(self, messages=None) -> None:\n",
      "    \"\"\"Initializes a new Chat object with the given messages, \n",
      "    or a default message if none are provided.\"\"\"\n",
      "\n",
      "def ask(self, question, max_tokens=2000, model=DEFAULT_MODEL, temperature=1, keep=True) -> str:\n",
      "    \"\"\"Sends a message to the GPT-3 API and returns the response.  \n",
      "    By default append the prompt and response to the chat history\"\"\" \n",
      "\n",
      "def get_topics(self) -> list:\n",
      "    \"\"\"Asks the chatgpt to provide up to three descriptive topics for the chat and returns them as a list.\"\"\"\n",
      "\n",
      "def suggest_filename(self):\n",
      "    \"\"\"Generates a suggested filename for saving the chat log.\"\"\"\n",
      "\n",
      "def summarise(self):\n",
      "    \"\"\"Asks the chatgpt to describe the chat in one sentence and returns the response.\"\"\"\n",
      "\n",
      "def save(self, path=None, directory='.'):\n",
      "    \"\"\"Save the chat to messages to a pickle (can be loaded again with load_chat)\"\"\"\n",
      "\n",
      "def format(self) -> str:\n",
      "    \"\"\"For mat the conversation text\"\"\"\n",
      "\n",
      "def print(self) -> None:\n",
      "    \"print formatted text of the conversation to screen\"\n",
      "\n",
      "def write_txt(self, path=None, directory='.'):\n",
      "    \"write formatted text of the converstaion to file\"\n",
      "``` \n",
      "\n",
      "`CodeInspector` class:\n",
      "\n",
      "```\n",
      "\"\"\"\n",
      "Subclass of Chat for inspecting a source code file\n",
      "\"\"\"\n",
      "\n",
      "def __init__(self, code_path) -> None:\n",
      "    \"\"\"Initializes a new CodeInspector object with the given code file path.\"\"\"\n",
      "\n",
      "def describe(self, temperature=0.2):\n",
      "    \"\"\"Asks the chatgpt to describe the purpose and algorithm for this code\"\"\"\n",
      "```\n",
      "\n",
      "`ChatDB` class:\n",
      "\n",
      "``` \n",
      "\"\"\"\n",
      "Represents a database of chat logs and provides methods for storing and searching logs.\n",
      "\"\"\"\n",
      "\n",
      "def __init__(self, path = None) -> None:\n",
      "    \"\"\"\n",
      "    Initializes a new ChatDB object with the database at the given path, or a default path if none is provided.\n",
      "\n",
      "    Args:\n",
      "    - path: The path to the database.\n",
      "    \"\"\"\n",
      "\n",
      "def store(self, chat: Chat, topics = []) -> None:\n",
      "    \"\"\"\n",
      "    Stores the given Chat object in the database.\n",
      "\n",
      "    Args:\n",
      "    - chat: The Chat object to store.\n",
      "    \"\"\"\n",
      "\n",
      "def summarise(self) -> PrettyTable:\n",
      "    \"\"\"\n",
      "    Prints a summary of all chats in the database to the console and returns a PrettyTable object.\n",
      "\n",
      "    Returns:\n",
      "    - A PrettyTable object representing the summary of all chats in the database.\n",
      "    \"\"\"\n",
      "\n",
      "def search(self, query) -> list:\n",
      "    \"\"\"\n",
      "    Searches the database for chats matching the given query and returns a list of Chat objects.\n",
      "\n",
      "    Args:\n",
      "    - query: The query to search for.\n",
      "\n",
      "    Returns:\n",
      "    - A list of Chat objects matching the query.\n",
      "    \"\"\"\n",
      "\n",
      "def close(self) -> None:\n",
      "    \"\"\"\n",
      "    Closes the database connection.\n",
      "    \"\"\"\n",
      "``` \n",
      "\n",
      "`load_chat` function:\n",
      "\n",
      "```\n",
      "\"\"\"\n",
      "Loads a Chat object from a pickle file at the given path.\n",
      "\n",
      "Args:\n",
      "- path: The path to the pickle file.\n",
      "\n",
      "Returns:\n",
      "- A Chat object.\n",
      "\"\"\"\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "new_chat.print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## and store it in the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.store(new_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----------------+-------------------------------+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "|         Name        |       Date      |             Topics            |                                                            Summary                                                            |\n",
      "+---------------------+-----------------+-------------------------------+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Code_Chatbot_OpenAI | 20230528_174323 | ['Code', 'Chatbot', 'OpenAI'] | This chat, named \"CodeChat\", is a chatbot designed to interact with and provide assistance on code using the OpenAI chat API. |\n",
      "|                     | 20230528_215454 |               []              |       Unfortunately, I don't have access to the chat history between us, so I am unable to describe it in one sentence.       |\n",
      "+---------------------+-----------------+-------------------------------+-------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Name</th>\n",
       "            <th>Date</th>\n",
       "            <th>Topics</th>\n",
       "            <th>Summary</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Code_Chatbot_OpenAI</td>\n",
       "            <td>20230528_174323</td>\n",
       "            <td>[&#x27;Code&#x27;, &#x27;Chatbot&#x27;, &#x27;OpenAI&#x27;]</td>\n",
       "            <td>This chat, named &quot;CodeChat&quot;, is a chatbot designed to interact with and provide assistance on code using the OpenAI chat API.</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td></td>\n",
       "            <td>20230528_215454</td>\n",
       "            <td>[]</td>\n",
       "            <td>Unfortunately, I don&#x27;t have access to the chat history between us, so I am unable to describe it in one sentence.</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+---------------------+-----------------+-------------------------------+-------------------------------------------------------------------------------------------------------------------------------+\n",
       "|         Name        |       Date      |             Topics            |                                                            Summary                                                            |\n",
       "+---------------------+-----------------+-------------------------------+-------------------------------------------------------------------------------------------------------------------------------+\n",
       "| Code_Chatbot_OpenAI | 20230528_174323 | ['Code', 'Chatbot', 'OpenAI'] | This chat, named \"CodeChat\", is a chatbot designed to interact with and provide assistance on code using the OpenAI chat API. |\n",
       "|                     | 20230528_215454 |               []              |       Unfortunately, I don't have access to the chat history between us, so I am unable to describe it in one sentence.       |\n",
       "+---------------------+-----------------+-------------------------------+-------------------------------------------------------------------------------------------------------------------------------+"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.summarise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but there is no chat log provided for me to describe in one sentence. The `Chat` class in the code above provides a method called `summarise()` that asks the OpenAI GPT-3 API to describe a chat log in one sentence. You would need to provide a chat log for the `Chat` object to describe in order to see an output from that method.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chat.summarise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are correct, there are several classes and methods in the file, and it would be possible to summarize them in a single docstring. However, some developers prefer to have a separate docstring for each class and method to provide more detailed information about its purpose, parameters and return type. This can make it easier for other developers to understand and use the code. Ultimately, the decision between a single docstring or separate docstrings is up to the style of the development team.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chat.ask(\"but there are several messages - why can't you summarise them?\", max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, you're right! A good summary is that the user requested docstrings to be written for the code. Thank you for pointing that out!\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chat.ask(\"surely a good summary is that the user asked you to write docstrings for the code?\", max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Unfortunately, I'm not sure which chat you're referring to. Could you please clarify?\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chat.summarise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can you please provide a concise docstring for the file, with a separate docstring for every class and method\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "Certainly! Here is a concise docstring for the file along with separate docstrings for every class and method:\n",
      "\n",
      "```\n",
      "\"\"\"\n",
      "This module provides classes for managing chat logs and code inspection.\n",
      "\n",
      "Classes:\n",
      "- Chat: Represents a chat log and provides methods for interacting with OpenAI's GPT-3 API.\n",
      "- CodeInspector: Represents a code file and provides methods for asking questions about the code.\n",
      "- ChatDB: Represents a database of chat logs and provides methods for storing and searching logs.\n",
      "\n",
      "Methods:\n",
      "- load_chat(path): Loads a Chat object from a pickle file at the given path.\n",
      "\"\"\"\n",
      "```\n",
      "\n",
      "`Chat` class:\n",
      "\n",
      "``` \n",
      "\"\"\"\n",
      "Represents a chat log and provides methods for interacting with OpenAI's GPT-3 API.\n",
      "\n",
      "Attributes:\n",
      "- messages: A list of dictionaries representing the chat messages, \n",
      "with each dictionary containing 'role' and 'content' keys.\n",
      "\"\"\"\n",
      "\n",
      "def __init__(self, messages=None) -> None:\n",
      "    \"\"\"Initializes a new Chat object with the given messages, \n",
      "    or a default message if none are provided.\"\"\"\n",
      "\n",
      "def ask(self, question, max_tokens=2000, model=DEFAULT_MODEL, temperature=1, keep=True) -> str:\n",
      "    \"\"\"Sends a message to the GPT-3 API and returns the response.  \n",
      "    By default append the prompt and response to the chat history\"\"\" \n",
      "\n",
      "def get_topics(self) -> list:\n",
      "    \"\"\"Asks the chatgpt to provide up to three descriptive topics for the chat and returns them as a list.\"\"\"\n",
      "\n",
      "def suggest_filename(self):\n",
      "    \"\"\"Generates a suggested filename for saving the chat log.\"\"\"\n",
      "\n",
      "def summarise(self):\n",
      "    \"\"\"Asks the chatgpt to describe the chat in one sentence and returns the response.\"\"\"\n",
      "\n",
      "def save(self, path=None, directory='.'):\n",
      "    \"\"\"Save the chat to messages to a pickle (can be loaded again with load_chat)\"\"\"\n",
      "\n",
      "def format(self) -> str:\n",
      "    \"\"\"For mat the conversation text\"\"\"\n",
      "\n",
      "def print(self) -> None:\n",
      "    \"print formatted text of the conversation to screen\"\n",
      "\n",
      "def write_txt(self, path=None, directory='.'):\n",
      "    \"write formatted text of the converstaion to file\"\n",
      "``` \n",
      "\n",
      "`CodeInspector` class:\n",
      "\n",
      "```\n",
      "\"\"\"\n",
      "Subclass of Chat for inspecting a source code file\n",
      "\"\"\"\n",
      "\n",
      "def __init__(self, code_path) -> None:\n",
      "    \"\"\"Initializes a new CodeInspector object with the given code file path.\"\"\"\n",
      "\n",
      "def describe(self, temperature=0.2):\n",
      "    \"\"\"Asks the chatgpt to describe the purpose and algorithm for this code\"\"\"\n",
      "```\n",
      "\n",
      "`ChatDB` class:\n",
      "\n",
      "``` \n",
      "\"\"\"\n",
      "Represents a database of chat logs and provides methods for storing and searching logs.\n",
      "\"\"\"\n",
      "\n",
      "def __init__(self, path = None) -> None:\n",
      "    \"\"\"\n",
      "    Initializes a new ChatDB object with the database at the given path, or a default path if none is provided.\n",
      "\n",
      "    Args:\n",
      "    - path: The path to the database.\n",
      "    \"\"\"\n",
      "\n",
      "def store(self, chat: Chat, topics = []) -> None:\n",
      "    \"\"\"\n",
      "    Stores the given Chat object in the database.\n",
      "\n",
      "    Args:\n",
      "    - chat: The Chat object to store.\n",
      "    \"\"\"\n",
      "\n",
      "def summarise(self) -> PrettyTable:\n",
      "    \"\"\"\n",
      "    Prints a summary of all chats in the database to the console and returns a PrettyTable object.\n",
      "\n",
      "    Returns:\n",
      "    - A PrettyTable object representing the summary of all chats in the database.\n",
      "    \"\"\"\n",
      "\n",
      "def search(self, query) -> list:\n",
      "    \"\"\"\n",
      "    Searches the database for chats matching the given query and returns a list of Chat objects.\n",
      "\n",
      "    Args:\n",
      "    - query: The query to search for.\n",
      "\n",
      "    Returns:\n",
      "    - A list of Chat objects matching the query.\n",
      "    \"\"\"\n",
      "\n",
      "def close(self) -> None:\n",
      "    \"\"\"\n",
      "    Closes the database connection.\n",
      "    \"\"\"\n",
      "``` \n",
      "\n",
      "`load_chat` function:\n",
      "\n",
      "```\n",
      "\"\"\"\n",
      "Loads a Chat object from a pickle file at the given path.\n",
      "\n",
      "Args:\n",
      "- path: The path to the pickle file.\n",
      "\n",
      "Returns:\n",
      "- A Chat object.\n",
      "\"\"\"\n",
      "```\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "but there are several messages - why can't you summarise them?\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "You are correct, there are several classes and methods in the file, and it would be possible to summarize them in a single docstring. However, some developers prefer to have a separate docstring for each class and method to provide more detailed information about its purpose, parameters and return type. This can make it easier for other developers to understand and use the code. Ultimately, the decision between a single docstring or separate docstrings is up to the style of the development team.\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "surely a good summary is that the user asked you to write docstrings for the code?\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "Yes, you're right! A good summary is that the user requested docstrings to be written for the code. Thank you for pointing that out!\n"
     ]
    }
   ],
   "source": [
    "new_chat.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are an expert in the Python language.'},\n",
       " {'role': 'user',\n",
       "  'content': 'Here is some code I want to ask questions about: \"\"\"\\nThis module provides classes for managing chat logs and code inspection.\\n\\nClasses:\\n- Chat: Represents a chat log and provides methods for interacting with OpenAI\\'s GPT-3 API.\\n- CodeInspector: Represents a code file and provides methods for asking questions about the code.\\n- ChatDB: Represents a database of chat logs and provides methods for storing and searching logs.\\n\\nMethods:\\n- load_chat(path): Loads a Chat object from a pickle file at the given path.\\n\"\"\"\\n\\n\\nimport datetime\\nimport json\\nimport os\\nimport pickle\\n\\nimport openai\\nfrom prettytable import PrettyTable\\nimport tinydb \\n\\nDEFAULT_MODEL = \\'gpt-3.5-turbo\\'\\n\\nclass Chat(object):\\n    \"\"\"\\n    Represents a chat log and provides methods for interacting with OpenAI\\'s GPT-3 API.\\n\\n    Attributes:\\n    - messages: A list of dictionaries representing the chat messages, \\n    with each dictionary containing \\'role\\' and \\'content\\' keys.\\n    \"\"\"\\n    print_from = 0\\n    def __init__(self, messages=None) -> None:\\n        \"\"\"Initializes a new Chat object with the given messages, \\n        or a default message if none are provided.\"\"\"\\n\\n        if messages is None:\\n            self.messages = messages=[\\n                {\"role\": \"system\", \"content\": \\'You are wise and helpful.\\'}]\\n        else:\\n            self.messages = messages\\n        \\n    def ask(self, question, max_tokens=2000, model=DEFAULT_MODEL, temperature=1, keep=True) -> str:\\n        \"\"\"Sends a message to the GPT-3 API and returns the response.  \\n        By default append the prompt and response to the chat history\"\"\" \\n\\n        messages = self.messages + [{\"role\": \"user\", \"content\": question}]\\n        completions = openai.ChatCompletion.create(\\n            model=model, messages=messages, max_tokens=max_tokens,\\n            temperature=temperature)\\n        answer = completions[\\'choices\\'][0][\\'message\\'][\\'content\\']\\n        messages.append({\"role\":\"assistant\", \"content\": answer})\\n        if keep:\\n            self.messages = messages\\n        return answer\\n    \\n    def get_topics(self) -> list:\\n        \"\"\"Asks the chatgpt to provide up to three descriptive topics for the chat and returns them as a list.\"\"\"\\n        a = self.ask(\\n            \\'Give me up to three descriptive one word topics for this chat, in a JSON list, \\'\\n            \\'with no introduction or explanation.  It is important that you use square brackets \\'\\n            \\'to format the list so that I can parse the output\\', \\n            max_tokens=40, keep=False, temperature = 0.2)\\n        return json.loads(a[a.index(\\'[\\'):a.index(\\']\\')+1])\\n\\n    def suggest_filename(self):\\n        \"\"\"Generates a suggested filename for saving the chat log.\"\"\"\\n        topics = self.get_topics()\\n\\n        filename = f\"{\\'_\\'.join(topics)}_{datetime.datetime.now().strftime(\\'%y%m%d_%H%M%S\\')}.pkl\"\\n\\n        return filename\\n    \\n    def summarise(self):\\n        \"\"\"Asks the chatgpt to describe the chat in one sentence and returns the response.\"\"\"\\n        a = self.ask(\\'Describe this chat in one sentence\\', max_tokens=200, keep=False)\\n        return a\\n\\n    def save(self, path=None, directory=\\'.\\'):\\n        \"\"\"Save the chat to messages to a pickle (can be loaded again with load_chat)\"\"\"\\n        if path is None:\\n            path = os.path.join(directory, self.suggest_filename())\\n        with open(path, \\'wb\\') as f:\\n            print(f\\'Saving Chat object to {path}\\')\\n            pickle.dump(self.messages, f)\\n\\n    def format(self) -> str:\\n        \"\"\"For mat the conversation text\"\"\"\\n        txt = \\'\\\\n\\\\n-----------------------------------------\\\\n\\\\n\\'.join(\\n            [msg[\\'content\\'] for msg in self.messages[self.print_from:]])\\n        return txt\\n\\n    def print(self) -> None:\\n        \"print formatted text of the conversation to screen\"\\n        print(self.format())\\n\\n    def write_txt(self, path=None, directory=\\'.\\'):\\n        \"write formatted text of the converstaion to file\"\\n        if path is None:\\n            path = os.path.join(directory, self.suggest_filename().replace(\\'.pkl\\', \\'.txt\\'))\\n\\n        txt = self.format()        \\n        with open(path, \\'w\\') as f:\\n            f.write(txt)\\n\\n        print(f\\'Saved chat log to {path}\\')\\n\\n\\nclass CodeInspector(Chat):\\n    \"\"\"Subclass of Chat for inspecting a source code file\"\"\"\\n    lang_map = {\\'py\\': \\'Python\\', \\'R\\': \\'R\\'}\\n    print_from = 2\\n \\n    def __init__(self, code_path) -> None:\\n        language = CodeInspector.lang_map[os.path.splitext(code_path)[1][1:]]\\n        with open(code_path) as f:\\n            self.code_path = code_path\\n            self.code = f.read()\\n        self.messages=[\\n            {\"role\": \"system\", \"content\": f\\'You are an expert in the {language} language.\\'},\\n            {\"role\": \"user\", \"content\": f\"Here is some code I want to ask questions about: {self.code}\"}]   \\n\\n\\n    def describe(self, temperature=0.2):\\n        self.ask(\\'Describe the purpose and algorithm for this code\\', temperature=temperature)\\n\\n\\nclass ChatDB(object):\\n    \"\"\"\\n    Represents a database of chat logs and provides methods for storing and searching logs.\\n\\n    Attributes:\\n    - db: A TinyDB object representing the database.\\n\\n    Methods:\\n    - __init__(path=None): Initializes a new ChatDB object with the database at the given path, or a default path if none is provided.\\n    - store(chat): Stores the given Chat object in the database.\\n    - summarise(): Prints a summary of all chats in the database to the console and returns a PrettyTable object.\\n    - search(query): Searches the database for chats matching the given query and returns a list of Chat objects.\\n    - close(): Closes the database connection.\\n    \"\"\"\\n        \\n    default_path = \\'./chats.json\\'\\n    \\n    def __init__(self, path = None) -> None:\\n        \"\"\"\\n        Initializes a new ChatDB object with the database at the given path, or a default path if none is provided.\\n\\n        Args:\\n        - path: The path to the database.\\n        \"\"\"\\n        if path is None:\\n            path = ChatDB.default_path\\n        self.db = tinydb.TinyDB(path)\\n\\n    def store(self, chat: Chat, topics = []) -> None:\\n        \"\"\"\\n        Stores the given Chat object in the database.\\n\\n        Args:\\n        - chat: The Chat object to store.\\n        \"\"\"\\n\\n        if not topics:\\n            try:      \\n                topics = chat.get_topics()\\n            except:\\n                Warning(\\'Model could not determine topics\\')\\n        name = \\'_\\'.join(topics)\\n        doc = {\\n            \\'name\\': name,\\n            \\'date\\': datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\\n            \\'topics\\': topics,\\n            \\'summary\\': chat.summarise(),\\n            \\'messages\\': chat.messages\\n        }\\n\\n        self.db.insert(doc)\\n\\n    def summarise(self) -> PrettyTable:\\n        \"\"\"\\n        Prints a summary of all chats in the database to the console and returns a PrettyTable object.\\n\\n        Returns:\\n        - A PrettyTable object representing the summary of all chats in the database.\\n        \"\"\"\\n        table = PrettyTable()\\n        table.field_names = [\\'Name\\', \\'Date\\', \\'Topics\\', \\'Summary\\']\\n        for doc in self.db:\\n            table.add_row([doc[k] for k in [\\'name\\', \\'date\\', \\'topics\\', \\'summary\\']])\\n        print(table)\\n        return table\\n    \\n    def search(self, query) -> list:\\n        \"\"\"\\n        Searches the database for chats matching the given query and returns a list of Chat objects.\\n\\n        Args:\\n        - query: The query to search for.\\n\\n        Returns:\\n        - A list of Chat objects matching the query.\\n        \"\"\"\\n        matches = self.db.search(query)\\n        return [Chat(doc[\\'messages\\']) for doc in matches]\\n    \\n    def close(self) -> None:\\n        \"\"\"\\n        Closes the database connection.\\n        \"\"\"\\n        self.db.close()\\n\\n\\n\\n\\ndef load_chat(path):\\n    \"\"\"\\n    Loads a Chat object from a pickle file at the given path.\\n\\n    Args:\\n    - path: The path to the pickle file.\\n\\n    Returns:\\n    - A Chat object.\\n    \"\"\"\\n    with open(path, \\'rb\\') as f:\\n        return Chat(pickle.load(f))'},\n",
       " {'role': 'user',\n",
       "  'content': 'can you please provide a concise docstring for the file, with a separate docstring for every class and method'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Certainly! Here is a concise docstring for the file along with separate docstrings for every class and method:\\n\\n```\\n\"\"\"\\nThis module provides classes for managing chat logs and code inspection.\\n\\nClasses:\\n- Chat: Represents a chat log and provides methods for interacting with OpenAI\\'s GPT-3 API.\\n- CodeInspector: Represents a code file and provides methods for asking questions about the code.\\n- ChatDB: Represents a database of chat logs and provides methods for storing and searching logs.\\n\\nMethods:\\n- load_chat(path): Loads a Chat object from a pickle file at the given path.\\n\"\"\"\\n```\\n\\n`Chat` class:\\n\\n``` \\n\"\"\"\\nRepresents a chat log and provides methods for interacting with OpenAI\\'s GPT-3 API.\\n\\nAttributes:\\n- messages: A list of dictionaries representing the chat messages, \\nwith each dictionary containing \\'role\\' and \\'content\\' keys.\\n\"\"\"\\n\\ndef __init__(self, messages=None) -> None:\\n    \"\"\"Initializes a new Chat object with the given messages, \\n    or a default message if none are provided.\"\"\"\\n\\ndef ask(self, question, max_tokens=2000, model=DEFAULT_MODEL, temperature=1, keep=True) -> str:\\n    \"\"\"Sends a message to the GPT-3 API and returns the response.  \\n    By default append the prompt and response to the chat history\"\"\" \\n\\ndef get_topics(self) -> list:\\n    \"\"\"Asks the chatgpt to provide up to three descriptive topics for the chat and returns them as a list.\"\"\"\\n\\ndef suggest_filename(self):\\n    \"\"\"Generates a suggested filename for saving the chat log.\"\"\"\\n\\ndef summarise(self):\\n    \"\"\"Asks the chatgpt to describe the chat in one sentence and returns the response.\"\"\"\\n\\ndef save(self, path=None, directory=\\'.\\'):\\n    \"\"\"Save the chat to messages to a pickle (can be loaded again with load_chat)\"\"\"\\n\\ndef format(self) -> str:\\n    \"\"\"For mat the conversation text\"\"\"\\n\\ndef print(self) -> None:\\n    \"print formatted text of the conversation to screen\"\\n\\ndef write_txt(self, path=None, directory=\\'.\\'):\\n    \"write formatted text of the converstaion to file\"\\n``` \\n\\n`CodeInspector` class:\\n\\n```\\n\"\"\"\\nSubclass of Chat for inspecting a source code file\\n\"\"\"\\n\\ndef __init__(self, code_path) -> None:\\n    \"\"\"Initializes a new CodeInspector object with the given code file path.\"\"\"\\n\\ndef describe(self, temperature=0.2):\\n    \"\"\"Asks the chatgpt to describe the purpose and algorithm for this code\"\"\"\\n```\\n\\n`ChatDB` class:\\n\\n``` \\n\"\"\"\\nRepresents a database of chat logs and provides methods for storing and searching logs.\\n\"\"\"\\n\\ndef __init__(self, path = None) -> None:\\n    \"\"\"\\n    Initializes a new ChatDB object with the database at the given path, or a default path if none is provided.\\n\\n    Args:\\n    - path: The path to the database.\\n    \"\"\"\\n\\ndef store(self, chat: Chat, topics = []) -> None:\\n    \"\"\"\\n    Stores the given Chat object in the database.\\n\\n    Args:\\n    - chat: The Chat object to store.\\n    \"\"\"\\n\\ndef summarise(self) -> PrettyTable:\\n    \"\"\"\\n    Prints a summary of all chats in the database to the console and returns a PrettyTable object.\\n\\n    Returns:\\n    - A PrettyTable object representing the summary of all chats in the database.\\n    \"\"\"\\n\\ndef search(self, query) -> list:\\n    \"\"\"\\n    Searches the database for chats matching the given query and returns a list of Chat objects.\\n\\n    Args:\\n    - query: The query to search for.\\n\\n    Returns:\\n    - A list of Chat objects matching the query.\\n    \"\"\"\\n\\ndef close(self) -> None:\\n    \"\"\"\\n    Closes the database connection.\\n    \"\"\"\\n``` \\n\\n`load_chat` function:\\n\\n```\\n\"\"\"\\nLoads a Chat object from a pickle file at the given path.\\n\\nArgs:\\n- path: The path to the pickle file.\\n\\nReturns:\\n- A Chat object.\\n\"\"\"\\n```'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chat.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I cannot provide you with up to three descriptive one word topics for this chat as I am an AI language model and I do not have access to the context of our conversation. However, if you want to get up to three descriptive one word topics for a chat, you can use the `get_topics()` method of the `Chat` class provided in the code you shared.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chat.ask(\n",
    "            'Give me up to three descriptive one word topics for this chat, in a JSON list, with no introduction or explanation', \n",
    "            max_tokens=400, keep=False, temperature = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but as an AI language model, I don't have access to the necessary context to provide you with a meaningful response to that question. Can you please provide more information or context about what you are asking?\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chat.ask(\n",
    "            'Give me up to three descriptive one word topics for this chat, in a JSON list, with no introduction or explanation', \n",
    "            max_tokens=400, keep=True, temperature = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ah, I see! In that case, based on the context of our conversation, the suggested topic words for this chat could be: \"Python\", \"documentation\", \"classes\". Would you like me to explain the concept of docstrings to you?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chat.ask('Surely \"docstrings\" is a potential topic?, and I only asked you to provide up to 3', max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python', 'documentation', 'classes']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chat.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_chat = Chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The recommended amount of sleep for adults is usually 7-9 hours per night. Generally, it is recommended that you establish a consistent sleep schedule and try to go to bed and wake up at the same time every day, even on weekends. Depending on what time you need to wake up in the morning, you can set a bedtime that allows you to get enough rest. For example, if you need to wake up at 6am, you should aim to go to bed between 9pm-11pm. Ultimately, the best bedtime for you depends on your individual needs and schedule.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chat.ask('what time should I go to bed?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Assuming you want to wake up at least two hours before tee off time to have breakfast, get ready, and arrive at the golf course with enough time to warm up, you should plan to wake up at around 5:00-5:30 AM. \\n\\nIf you want to get 7-9 hours of sleep, and counting back from your wake-up time, you should aim to go to bed between 8:15-10:15 PM. \\n\\nOf course, this schedule can be adjusted based on your personal preferences and what time you are used to waking up and going to bed.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chat.ask('so when should I go to sleep if I want to tee off at 7:15AM?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"If you plan to wake up just one hour before your tee time, then you should consider getting enough sleep according to your bodyâ€™s requirements. Some people can function very well with just 6 hours of sleep, while others need at least 8 hours to feel rested the next day. \\n\\nAssuming you need 7-8 hours of sleep to feel well-rested, you should plan to go to bed between 10:15-11:15 PM the night before your tee time. However, it's important to note that getting less than the recommended amount of sleep may affect your focus, performance, and enjoyment of the game.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chat.ask('I think I can probably wake up only 1 hour before my tee time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This chat involved asking and receiving advice on the appropriate bedtime in order to wake up on time for a 7:15 AM tee off.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chat.summarise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.store(new_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----------------+-------------------------------+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "|         Name        |       Date      |             Topics            |                                                            Summary                                                            |\n",
      "+---------------------+-----------------+-------------------------------+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Code_Chatbot_OpenAI | 20230528_174323 | ['Code', 'Chatbot', 'OpenAI'] | This chat, named \"CodeChat\", is a chatbot designed to interact with and provide assistance on code using the OpenAI chat API. |\n",
      "|                     | 20230528_215454 |               []              |       Unfortunately, I don't have access to the chat history between us, so I am unable to describe it in one sentence.       |\n",
      "|   Sleep_Golf_Time   | 20230528_221409 |   ['Sleep', 'Golf', 'Time']   |                       This chat was about sleep, bedtimes, and scheduling for an early morning tee time.                      |\n",
      "+---------------------+-----------------+-------------------------------+-------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Name</th>\n",
       "            <th>Date</th>\n",
       "            <th>Topics</th>\n",
       "            <th>Summary</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Code_Chatbot_OpenAI</td>\n",
       "            <td>20230528_174323</td>\n",
       "            <td>[&#x27;Code&#x27;, &#x27;Chatbot&#x27;, &#x27;OpenAI&#x27;]</td>\n",
       "            <td>This chat, named &quot;CodeChat&quot;, is a chatbot designed to interact with and provide assistance on code using the OpenAI chat API.</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td></td>\n",
       "            <td>20230528_215454</td>\n",
       "            <td>[]</td>\n",
       "            <td>Unfortunately, I don&#x27;t have access to the chat history between us, so I am unable to describe it in one sentence.</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Sleep_Golf_Time</td>\n",
       "            <td>20230528_221409</td>\n",
       "            <td>[&#x27;Sleep&#x27;, &#x27;Golf&#x27;, &#x27;Time&#x27;]</td>\n",
       "            <td>This chat was about sleep, bedtimes, and scheduling for an early morning tee time.</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+---------------------+-----------------+-------------------------------+-------------------------------------------------------------------------------------------------------------------------------+\n",
       "|         Name        |       Date      |             Topics            |                                                            Summary                                                            |\n",
       "+---------------------+-----------------+-------------------------------+-------------------------------------------------------------------------------------------------------------------------------+\n",
       "| Code_Chatbot_OpenAI | 20230528_174323 | ['Code', 'Chatbot', 'OpenAI'] | This chat, named \"CodeChat\", is a chatbot designed to interact with and provide assistance on code using the OpenAI chat API. |\n",
       "|                     | 20230528_215454 |               []              |       Unfortunately, I don't have access to the chat history between us, so I am unable to describe it in one sentence.       |\n",
       "|   Sleep_Golf_Time   | 20230528_221409 |   ['Sleep', 'Golf', 'Time']   |                       This chat was about sleep, bedtimes, and scheduling for an early morning tee time.                      |\n",
       "+---------------------+-----------------+-------------------------------+-------------------------------------------------------------------------------------------------------------------------------+"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.summarise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "substring not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m db\u001b[39m.\u001b[39;49mstore(new_chat)\n",
      "File \u001b[1;32mc:\\Users\\DavisC\\sandpit\\aipy\\aipy\\ai.py:163\u001b[0m, in \u001b[0;36mChatDB.store\u001b[1;34m(self, chat)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstore\u001b[39m(\u001b[39mself\u001b[39m, chat: Chat) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    156\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[39m    Stores the given Chat object in the database.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \n\u001b[0;32m    159\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[39m    - chat: The Chat object to store.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 163\u001b[0m     topics \u001b[39m=\u001b[39m chat\u001b[39m.\u001b[39;49mget_topics()\n\u001b[0;32m    164\u001b[0m     name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(topics)\n\u001b[0;32m    165\u001b[0m     doc \u001b[39m=\u001b[39m {\n\u001b[0;32m    166\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m: name,\n\u001b[0;32m    167\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m: datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%\u001b[39m\u001b[39mH\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m'\u001b[39m: chat\u001b[39m.\u001b[39mmessages\n\u001b[0;32m    171\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\DavisC\\sandpit\\aipy\\aipy\\ai.py:63\u001b[0m, in \u001b[0;36mChat.get_topics\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Asks the chatgpt to provide up to three descriptive topics for the chat and returns them as a list.\"\"\"\u001b[39;00m\n\u001b[0;32m     60\u001b[0m a \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mask(\n\u001b[0;32m     61\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mGive me up to three descriptive one word topics for this chat, in a JSON list, with no introduction or explanation\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[0;32m     62\u001b[0m     max_tokens\u001b[39m=\u001b[39m\u001b[39m40\u001b[39m, keep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, temperature \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m)\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m json\u001b[39m.\u001b[39mloads(a[a\u001b[39m.\u001b[39mindex(\u001b[39m'\u001b[39m\u001b[39m[\u001b[39m\u001b[39m'\u001b[39m):a\u001b[39m.\u001b[39;49mindex(\u001b[39m'\u001b[39;49m\u001b[39m]\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: substring not found"
     ]
    }
   ],
   "source": [
    "db.store(new_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are an expert in the Python language.'},\n",
       " {'role': 'user',\n",
       "  'content': 'Here is some code I want to ask questions about: \"\"\"\\nThis module provides classes for managing chat logs and code inspection.\\n\\nClasses:\\n- Chat: Represents a chat log and provides methods for interacting with OpenAI\\'s GPT-3 API.\\n- CodeInspector: Represents a code file and provides methods for asking questions about the code.\\n- ChatDB: Represents a database of chat logs and provides methods for storing and searching logs.\\n\\nMethods:\\n- load_chat(path): Loads a Chat object from a pickle file at the given path.\\n\"\"\"\\n\\n\\nimport datetime\\nimport json\\nimport os\\nimport pickle\\n\\nimport openai\\nfrom prettytable import PrettyTable\\nimport tinydb \\n\\nDEFAULT_MODEL = \\'gpt-3.5-turbo\\'\\n\\nclass Chat(object):\\n    \"\"\"\\n    Represents a chat log and provides methods for interacting with OpenAI\\'s GPT-3 API.\\n\\n    Attributes:\\n    - messages: A list of dictionaries representing the chat messages, \\n    with each dictionary containing \\'role\\' and \\'content\\' keys.\\n    \"\"\"\\n    print_from = 0\\n    def __init__(self, messages=None) -> None:\\n        \"\"\"Initializes a new Chat object with the given messages, \\n        or a default message if none are provided.\"\"\"\\n\\n        if messages is None:\\n            self.messages = messages=[\\n                {\"role\": \"system\", \"content\": \\'You are wise and helpful.\\'}]\\n        else:\\n            self.messages = messages\\n        \\n    def ask(self, question, max_tokens=2000, model=DEFAULT_MODEL, temperature=1, keep=True) -> str:\\n        \"\"\"Sends a message to the GPT-3 API and returns the response.  \\n        By default append the prompt and response to the chat history\"\"\" \\n\\n        messages = self.messages + [{\"role\": \"user\", \"content\": question}]\\n        completions = openai.ChatCompletion.create(\\n            model=model, messages=messages, max_tokens=max_tokens,\\n            temperature=temperature)\\n        answer = completions[\\'choices\\'][0][\\'message\\'][\\'content\\']\\n        messages.append({\"role\":\"assistant\", \"content\": answer})\\n        if keep:\\n            self.messages = messages\\n        return answer\\n    \\n    def get_topics(self) -> list:\\n        \"\"\"Asks the chatgpt to provide up to three descriptive topics for the chat and returns them as a list.\"\"\"\\n        a = self.ask(\\n            \\'Give me up to three descriptive one word topics for this chat, in a JSON list, with no introduction or explanation\\', \\n            max_tokens=40, keep=False, temperature = 0.2)\\n        return json.loads(a[a.index(\\'[\\'):a.index(\\']\\')+1])\\n\\n    def suggest_filename(self):\\n        \"\"\"Generates a suggested filename for saving the chat log.\"\"\"\\n        topics = self.get_topics()\\n\\n        filename = f\"{\\'_\\'.join(topics)}_{datetime.datetime.now().strftime(\\'%y%m%d_%H%M%S\\')}.pkl\"\\n\\n        return filename\\n    \\n    def summarise(self):\\n        \"\"\"Asks the chatgpt to describe the chat in one sentence and returns the response.\"\"\"\\n        a = self.ask(\\'Describe this chat in one sentence\\', max_tokens=200, keep=False)\\n        return a\\n\\n    def save(self, path=None, directory=\\'.\\'):\\n        \"\"\"Save the chat to messages to a pickle (can be loaded again with load_chat)\"\"\"\\n        if path is None:\\n            path = os.path.join(directory, self.suggest_filename())\\n        with open(path, \\'wb\\') as f:\\n            print(f\\'Saving Chat object to {path}\\')\\n            pickle.dump(self.messages, f)\\n\\n    def format(self) -> str:\\n        \"\"\"For mat the conversation text\"\"\"\\n        txt = \\'\\\\n\\\\n-----------------------------------------\\\\n\\\\n\\'.join(\\n            [msg[\\'content\\'] for msg in self.messages[self.print_from:]])\\n        return txt\\n\\n    def print(self) -> None:\\n        \"print formatted text of the conversation to screen\"\\n        print(self.format())\\n\\n    def write_txt(self, path=None, directory=\\'.\\'):\\n        \"write formatted text of the converstaion to file\"\\n        if path is None:\\n            path = os.path.join(directory, self.suggest_filename().replace(\\'.pkl\\', \\'.txt\\'))\\n\\n        txt = self.format()        \\n        with open(path, \\'w\\') as f:\\n            f.write(txt)\\n\\n        print(f\\'Saved chat log to {path}\\')\\n\\n\\nclass CodeInspector(Chat):\\n    \"\"\"Subclass of Chat for inspecting a source code file\"\"\"\\n    lang_map = {\\'py\\': \\'Python\\', \\'R\\': \\'R\\'}\\n    print_from = 2\\n \\n    def __init__(self, code_path) -> None:\\n        language = CodeInspector.lang_map[os.path.splitext(code_path)[1][1:]]\\n        with open(code_path) as f:\\n            self.code_path = code_path\\n            self.code = f.read()\\n        self.messages=[\\n            {\"role\": \"system\", \"content\": f\\'You are an expert in the {language} language.\\'},\\n            {\"role\": \"user\", \"content\": f\"Here is some code I want to ask questions about: {self.code}\"}]   \\n\\n\\n    def describe(self, temperature=0.2):\\n        self.ask(\\'Describe the purpose and algorithm for this code\\', temperature=temperature)\\n\\n\\nclass ChatDB(object):\\n    \"\"\"\\n    Represents a database of chat logs and provides methods for storing and searching logs.\\n\\n    Attributes:\\n    - db: A TinyDB object representing the database.\\n\\n    Methods:\\n    - __init__(path=None): Initializes a new ChatDB object with the database at the given path, or a default path if none is provided.\\n    - store(chat): Stores the given Chat object in the database.\\n    - summarise(): Prints a summary of all chats in the database to the console and returns a PrettyTable object.\\n    - search(query): Searches the database for chats matching the given query and returns a list of Chat objects.\\n    - close(): Closes the database connection.\\n    \"\"\"\\n        \\n    default_path = \\'./chats.json\\'\\n    \\n    def __init__(self, path = None) -> None:\\n        \"\"\"\\n        Initializes a new ChatDB object with the database at the given path, or a default path if none is provided.\\n\\n        Args:\\n        - path: The path to the database.\\n        \"\"\"\\n        if path is None:\\n            path = ChatDB.default_path\\n        self.db = tinydb.TinyDB(path)\\n\\n    def store(self, chat: Chat) -> None:\\n        \"\"\"\\n        Stores the given Chat object in the database.\\n\\n        Args:\\n        - chat: The Chat object to store.\\n        \"\"\"\\n\\n        topics = chat.get_topics()\\n        name = \\'_\\'.join(topics)\\n        doc = {\\n            \\'name\\': name,\\n            \\'date\\': datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\\n            \\'topics\\': topics,\\n            \\'summary\\': chat.summarise(),\\n            \\'messages\\': chat.messages\\n        }\\n\\n        self.db.insert(doc)\\n\\n    def summarise(self) -> PrettyTable:\\n        \"\"\"\\n        Prints a summary of all chats in the database to the console and returns a PrettyTable object.\\n\\n        Returns:\\n        - A PrettyTable object representing the summary of all chats in the database.\\n        \"\"\"\\n        table = PrettyTable()\\n        table.field_names = [\\'Name\\', \\'Date\\', \\'Topics\\', \\'Summary\\']\\n        for doc in self.db:\\n            table.add_row([doc[k] for k in [\\'name\\', \\'date\\', \\'topics\\', \\'summary\\']])\\n        print(table)\\n        return table\\n    \\n    def search(self, query) -> list:\\n        \"\"\"\\n        Searches the database for chats matching the given query and returns a list of Chat objects.\\n\\n        Args:\\n        - query: The query to search for.\\n\\n        Returns:\\n        - A list of Chat objects matching the query.\\n        \"\"\"\\n        matches = self.db.search(query)\\n        return [Chat(doc[\\'messages\\']) for doc in matches]\\n    \\n    def close(self) -> None:\\n        \"\"\"\\n        Closes the database connection.\\n        \"\"\"\\n        self.db.close()\\n\\n\\n\\n\\ndef load_chat(path):\\n    \"\"\"\\n    Loads a Chat object from a pickle file at the given path.\\n\\n    Args:\\n    - path: The path to the pickle file.\\n\\n    Returns:\\n    - A Chat object.\\n    \"\"\"\\n    with open(path, \\'rb\\') as f:\\n        return Chat(pickle.load(f))'},\n",
       " {'role': 'user',\n",
       "  'content': 'can you please provide a concise docstring for the file, with a separate docstring for every class and method'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Sure, here it is:\\n\\n```\\nThis module provides classes for managing chat logs and code inspection.\\n\\nClasses:\\n- Chat: Represents a chat log and provides methods for interacting with OpenAI\\'s GPT-3 API.\\n- CodeInspector: Represents a code file and provides methods for asking questions about the code.\\n- ChatDB: Represents a database of chat logs and provides methods for storing and searching logs.\\n\\nMethods:\\n- load_chat(path): Loads a Chat object from a pickle file at the given path.\\n\"\"\"\\n\\nClass Chat:\\n    \"\"\"\\n    Represents a chat log and provides methods for interacting with OpenAI\\'s GPT-3 API.\\n\\n    Attributes:\\n    - messages: A list of dictionaries representing the chat messages, \\n    with each dictionary containing \\'role\\' and \\'content\\' keys.\\n    \"\"\"\\n\\n    def __init__(self, messages=None) -> None:\\n        \"\"\"\\n        Initializes a new Chat object with the given messages, \\n        or a default message if none are provided.\\n\\n        Args:\\n        - messages: A list of message dictionaries to start the chat with.\\n        \"\"\"\\n        \\n    def ask(self, question, max_tokens=2000, model=DEFAULT_MODEL, temperature=1, keep=True) -> str:\\n        \"\"\"\\n        Sends a message to the GPT-3 API and returns the response.  \\n        By default append the prompt and response to the chat history\\n\\n        Args:\\n        - question: The message to send to the API.\\n        - max_tokens: The maximum number of tokens to generate in the response.\\n        - model: The name of the model to use for generation.\\n        - temperature: The sampling temperature to use for generation.\\n        - keep: Whether to keep the new message in the chat log.\\n\\n        Returns:\\n        - The response from the API.\\n        \"\"\"\\n        \\n    def get_topics(self) -> list:\\n        \"\"\"\\n        Asks the chatgpt to provide up to three descriptive topics for the chat and returns them as a list.\\n\\n        Returns:\\n        - A list of up to three descriptive topics for the chat.\\n        \"\"\"\\n        \\n    def suggest_filename(self):\\n        \"\"\"\\n        Generates a suggested filename for saving the chat log.\\n\\n        Returns:\\n        - A suggested filename for the chat log.\\n        \"\"\"\\n        \\n    def summarise(self):\\n        \"\"\"\\n        Asks the chatgpt to describe the chat in one sentence and returns the response.\\n\\n        Returns:\\n        - A one-sentence summary of the chat.\\n        \"\"\"\\n        \\n    def save(self, path=None, directory=\\'.\\'):\\n        \"\"\"\\n        Save the chat to messages to a pickle (can be loaded again with load_chat)\\n\\n        Args:\\n        - path: The path to save the chat log to.\\n        - directory: The directory to save the chat log in.\\n        \"\"\"\\n        \\n    def format(self) -> str:\\n        \"\"\"\\n        Formats the conversation text.\\n\\n        Returns:\\n        - A string with the formatted conversation text.\\n        \"\"\"\\n        \\n    def print(self) -> None:\\n        \"\"\"\\n        Prints the formatted conversation text to the console.\\n        \"\"\"\\n        \\n    def write_txt(self, path=None, directory=\\'.\\'):\\n        \"\"\"\\n        Writes the formatted conversation text to a text file.\\n\\n        Args:\\n        - path: The path to save the text file to.\\n        - directory: The directory to save the text file in.\\n        \"\"\"\\n        \\nClass CodeInspector(Chat):\\n    \"\"\"\\n    Subclass of Chat for inspecting a source code file.\\n    \"\"\"\\n    \\n    def __init__(self, code_path) -> None:\\n        \"\"\"\\n        Initializes a new CodeInspector object with the given code file.\\n\\n        Args:\\n        - code_path: The path to the code file.\\n        \"\"\" \\n        \\n    def describe(self, temperature=0.2):\\n        \"\"\"\\n        Asks the chatgpt to describe the purpose and algorithm for the code.\\n\\n        Args:\\n        - temperature: The sampling temperature to use for generation.\\n        \"\"\"\\n        \\nClass ChatDB(object):\\n    \"\"\"\\n    Represents a database of chat logs and provides methods for storing and searching logs.\\n    \"\"\"\\n        \\n    def __init__(self, path = None) -> None:\\n        \"\"\"\\n        Initializes a new ChatDB object with the database at the given path, \\n        or a default path if none is provided.\\n\\n        Args:\\n        - path: The path to the database.\\n        \"\"\"\\n        \\n    def store(self, chat: Chat) -> None:\\n        \"\"\"\\n        Stores the given Chat object in the database.\\n\\n        Args:\\n        - chat: The Chat object to store.\\n        \"\"\"\\n        \\n    def summarise(self) -> PrettyTable:\\n        \"\"\"\\n        Prints a summary of all chats in the database to the console and returns a PrettyTable object.\\n\\n        Returns:\\n        - A PrettyTable object representing the summary of all chats in the database.\\n        \"\"\"\\n        \\n    def search(self, query) -> list:\\n        \"\"\"\\n        Searches the database for chats matching the given query and returns a list of Chat objects.\\n\\n        Args:\\n        - query: The query to search for.\\n\\n        Returns:\\n        - A list of Chat objects matching the query.\\n        \"\"\"\\n        \\n    def close(self) -> None:\\n        \"\"\"\\n        Closes the database connection.\\n        \"\"\"\\n        \\ndef load_chat(path):\\n    \"\"\"\\n    Loads a Chat object from a pickle file at the given path.\\n\\n    Args:\\n    - path: The path to the pickle file.\\n\\n    Returns:\\n    - A Chat object.\\n    \"\"\"\\n```'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chat.messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = db.search(Query().topics.any('Code'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert in the Python language.\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "Here is some code I want to ask questions about: import openai\n",
      "import os\n",
      "\n",
      "DEFAULT_MODEL = 'gpt-3.5-turbo'\n",
      "\n",
      "class Chat(object):\n",
      "    def __init__(self) -> None:\n",
      "        self.messages = messages=[\n",
      "            {\"role\": \"system\", \"content\": 'You are wise and helpful.'}]\n",
      "        \n",
      "    def ask(self, question, max_tokens=2000, model=DEFAULT_MODEL, temperature=1):\n",
      "        messages = self.messages + [{\"role\": \"user\", \"content\": question}]\n",
      "        completions = openai.ChatCompletion.create(\n",
      "            model=model, messages=messages, max_tokens=max_tokens,\n",
      "            temperature=temperature)\n",
      "        answer = completions['choices'][0]['message']['content']\n",
      "        messages.append({\"role\":\"assistant\", \"content\": answer})\n",
      "        self.messages = messages\n",
      "        return completions\n",
      "\n",
      "\n",
      "class CodeInspector(Chat):\n",
      "    lang_map = {'py': 'Python', 'R': 'R'}\n",
      " \n",
      "    def __init__(self, code_path) -> None:\n",
      "        language = CodeInspector.lang_map[os.path.splitext(code_path)[1][1:]]\n",
      "        with open(code_path) as file:\n",
      "            self.code_path = code_path\n",
      "            self.code = file.read()\n",
      "        self.messages=[\n",
      "            {\"role\": \"system\", \"content\": f'You are an expert in the {language} language.'},\n",
      "            {\"role\": \"user\", \"content\": f\"Here is some code I want to ask questions about: {self.code}\"}]   \n",
      "\n",
      "    def ask(self, question, temperature=0.2):\n",
      "        return super().ask(question, temperature=temperature)\n",
      "\n",
      "    def describe(self, temperature=0.2):\n",
      "        self.ask('Describe the purpose and algorithm for this code', temperature=temperature)\n",
      "\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "Describe the purpose and algorithm for this code\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "This code defines two classes: `Chat` and `CodeInspector`. \n",
      "\n",
      "The `Chat` class is used to interact with the OpenAI chat API. It has an `ask` method that takes a question as input and returns a response from the API. The `messages` attribute of the class is used to keep track of the conversation history.\n",
      "\n",
      "The `CodeInspector` class is a subclass of `Chat` and is used to inspect code files. It takes a path to a code file as input and reads the code from the file. It also has a `describe` method that calls the `ask` method of the `Chat` class to ask for a description of the purpose and algorithm of the code. The language of the code is determined based on the file extension and is used to provide a system message at initialization.\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "is the code any good?\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "It's difficult to say whether the code is \"good\" without more context about what it's intended to do and how it's being used. \n",
      "\n",
      "However, the code appears to be well-structured and follows best practices for object-oriented programming in Python. It also makes use of the OpenAI API to interact with a chatbot, which is a useful feature for certain applications.\n",
      "\n",
      "That being said, there may be specific areas for improvement depending on the specific use case and requirements.\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "can you give me a short name for this chat\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "Sure, how about \"CodeChat\"? It's short, easy to remember, and reflects the fact that the chatbot is designed to interact with code.\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "give me a short name for this chat that would be an informative and unique key in a database.  Unless this is impossible, just give me the name, nothing else\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "How about \"CC-OpenAI\"? It includes the abbreviation for \"CodeChat\" and the name of the API being used, making it both informative and unique.\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "how should I save the message list for this chat to disk, so that I can load it and pick up where we left off?\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "One way to save the message list for this chat to disk is by using the `pickle` module in Python. Here's an example of how you can save and load the message list:\n",
      "\n",
      "```python\n",
      "import pickle\n",
      "\n",
      "# Save the message list to disk\n",
      "with open('messages.pkl', 'wb') as f:\n",
      "    pickle.dump(messages, f)\n",
      "\n",
      "# Load the message list from disk\n",
      "with open('messages.pkl', 'rb') as f:\n",
      "    messages = pickle.load(f)\n",
      "```\n",
      "\n",
      "In this example, the `pickle.dump()` function is used to save the `messages` list to a file named `messages.pkl`. The `wb` argument specifies that the file should be opened in write mode and in binary format.\n",
      "\n",
      "To load the message list from disk, the `pickle.load()` function is used to read the contents of the `messages.pkl` file into a new variable named `messages`. The `rb` argument specifies that the file should be opened in read mode and in binary format.\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "what if I want to store multiple chats so they can be selected and loaded from a list short descriptions?  a document store database?\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "If you want to store multiple chats so they can be selected and loaded from a list of short descriptions, you can use a document store database like MongoDB. \n",
      "\n",
      "In MongoDB, you can create a collection to store the chats, where each document in the collection represents a single chat. Each document can have fields for the chat name, description, and the message list. Here's an example of what a chat document might look like:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"name\": \"CodeChat\",\n",
      "    \"description\": \"A chatbot for interacting with code\",\n",
      "    \"messages\": [\n",
      "        {\"role\": \"system\", \"content\": \"Welcome to CodeChat!\"},\n",
      "        {\"role\": \"user\", \"content\": \"Can you help me with this code?\"},\n",
      "        {\"role\": \"assistant\", \"content\": \"Sure, what do you need help with?\"}\n",
      "    ]\n",
      "}\n",
      "```\n",
      "\n",
      "To load a chat from the database, you can query the collection for the chat document based on its name or description. Once you have the document, you can extract the message list and use it to initialize a new instance of the `Chat` or `CodeInspector` class.\n",
      "\n",
      "Here's an example of how you can load a chat from MongoDB using the `pymongo` module in Python:\n",
      "\n",
      "```python\n",
      "import pymongo\n",
      "\n",
      "# Connect to the MongoDB server\n",
      "client = pymongo.MongoClient('mongodb://localhost:27017/')\n",
      "\n",
      "# Select the database and collection\n",
      "db = client['my_database']\n",
      "chats = db['chats']\n",
      "\n",
      "# Query the collection for the chat document\n",
      "chat_doc = chats.find_one({'name': 'CodeChat'})\n",
      "\n",
      "# Extract the message list from the chat document\n",
      "messages = chat_doc['messages']\n",
      "\n",
      "# Initialize a new instance of the Chat class with the message list\n",
      "chat = Chat()\n",
      "chat.messages = messages\n",
      "```\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "I'm not sure I can setup a mongodb database on my laptop, because I don't have admin rights.  Would tinydb do the same thing?\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "Yes, `tinydb` can be used as a lightweight alternative to MongoDB for storing chat data on a local machine. \n",
      "\n",
      "`tinydb` is a document-oriented database that stores data in JSON format, making it easy to read and write data to disk. It can be used to store multiple chats in a single file, with each chat represented as a separate document in the database.\n",
      "\n",
      "Here's an example of how you can use `tinydb` to store and load chat data:\n",
      "\n",
      "```python\n",
      "from tinydb import TinyDB, Query\n",
      "\n",
      "# Create a new database file\n",
      "db = TinyDB('chats.json')\n",
      "\n",
      "# Insert a new chat document into the database\n",
      "chat_doc = {\n",
      "    \"name\": \"CodeChat\",\n",
      "    \"description\": \"A chatbot for interacting with code\",\n",
      "    \"messages\": [\n",
      "        {\"role\": \"system\", \"content\": \"Welcome to CodeChat!\"},\n",
      "        {\"role\": \"user\", \"content\": \"Can you help me with this code?\"},\n",
      "        {\"role\": \"assistant\", \"content\": \"Sure, what do you need help with?\"}\n",
      "    ]\n",
      "}\n",
      "db.insert(chat_doc)\n",
      "\n",
      "# Query the database for the chat document\n",
      "Chat = Query()\n",
      "chat_doc = db.get(Chat.name == 'CodeChat')\n",
      "\n",
      "# Extract the message list from the chat document\n",
      "messages = chat_doc['messages']\n",
      "\n",
      "# Initialize a new instance of the Chat class with the message list\n",
      "chat = Chat()\n",
      "chat.messages = messages\n",
      "```\n",
      "\n",
      "In this example, a new `TinyDB` object is created with a filename of `chats.json`. A new chat document is inserted into the database using the `insert()` method.\n",
      "\n",
      "To load a chat from the database, the `get()` method is used to query the database for the chat document based on its name. Once the document is retrieved, the message list is extracted and used to initialize a new instance of the `Chat` or `CodeInspector` class.\n"
     ]
    }
   ],
   "source": [
    "matches[0].print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
